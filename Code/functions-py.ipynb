{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling MNI\n",
    "<ol>\n",
    "    <li> ball_set\n",
    "    <li> coord2coord\n",
    "    <li> mni2region \n",
    "    <li> mni2cl_region\n",
    "    <li> set_dictionaries_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#------------------ set_dictionaries_rois --------------\n",
    "#Set the dictionaries and the list of attributes for \n",
    "#function r_info\n",
    "#Input: - file_info: file with json dictionaries\n",
    "#       - file_nodes: file with json  attributes\n",
    "#Output: - r_info: with those file sets \n",
    "#----------------- r_info -----------------\n",
    "#Gives information of nodes of the given Atlas (Shen for me)\n",
    "#Input: i: number of the region\n",
    "#Output result: dictionarie with the MNI coordinates,\n",
    "#      lobe, network and Brodmann area of region i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------ ball_set -----------------------\n",
    "def ball_set(center,r):\n",
    "    \"\"\" Generates the ball of integer coordinates of a ball with \n",
    "    integer center and radius r\n",
    "    Input: - center: center of ball\n",
    "           - r: radius of ball    \n",
    "    Output:- set of coordinates into the ball\n",
    "    \"\"\"\n",
    "    center=np.array(center)\n",
    "    l=np.arange(-(r*r),(r*r)+1,1)\n",
    "    lista=[]\n",
    "    for element in it.product(l,l,l):\n",
    "        norm=np.linalg.norm(element)\n",
    "        if (norm*norm) <= (r*r):\n",
    "            lista=lista+[center+element]\n",
    "    return(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------coord2coord-----------------------------\n",
    "def coord2coord(coord,aff):\n",
    "    \"\"\"\n",
    "    This function gives one coordinate and returns the coordinate \n",
    "    after applying the affine matrix\n",
    "    Input: -coord: coordinate\n",
    "           -aff: Affine matrix(4x4)\n",
    "    Output -new_coord: new coordinate\n",
    "    \"\"\"\n",
    "    import nibabel as nib\n",
    "    coord=np.array(coord)\n",
    "    \n",
    "    vround = np.vectorize(my_round)\n",
    "    vint=np.vectorize(int)\n",
    "    \n",
    "    new_coord=nib.affines.apply_affine(aff,coord) #coord to new_coord\n",
    "    new_coord=vint(vround(new_coord))\n",
    "    \n",
    "    return(new_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- mni2region -----------------------\n",
    "def mni2region(coord,nii):\n",
    "    \"\"\"\n",
    "    This function gives the index of the region in the atlas\n",
    "    for the given MNI coordinate \n",
    "    Input: - coord: MNI coordinate\n",
    "           - nii: Atlas as nib object \n",
    "    Output: -index of region\n",
    "    \"\"\"\n",
    "    coord=np.array(coord)\n",
    "    atlas=nii.get_fdata()\n",
    "    aff=nii.affine\n",
    "    vox=coord2coord(coord,np.linalg.inv(aff))\n",
    "    \n",
    "    r=atlas[vox[0],vox[1],vox[2]]\n",
    "    return(int(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- mni2cl_region -----------------------\n",
    "def mni2cl_region(coord,atlas):\n",
    "    \"\"\"\n",
    "    This function gives the index of the region in the atlas\n",
    "    for the given MNI coordinate (or the most closests)\n",
    "    Input: - coord: MNI coordinate\n",
    "           - atlas: Atlas \n",
    "    Output: -index of region\n",
    "    \"\"\"\n",
    "    r=mni2region(coord,atlas)\n",
    "    if r==0:\n",
    "        R=0\n",
    "        neighs=set()\n",
    "        while True:\n",
    "            R=R+1\n",
    "            print(R)\n",
    "            coord=np.array(coord)\n",
    "            neigh2={tuple(row) for row in ball_set(coord,np.sqrt(R)) } #set of ball_set\n",
    "            neigh=neigh2-neighs #minus the last ball_set\n",
    "            neighs=neigh2\n",
    "            poss_r=[mni2region(coords,atlas) for coords in neigh]\n",
    "            poss_r=set(poss_r) - {0} #take away 0 values\n",
    "            if len(poss_r)>0:\n",
    "                return (list(poss_r))\n",
    "                break\n",
    "    else:\n",
    "        return([r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dictionaries_rois(file_info,file_nodes):\n",
    "    \"\"\" \n",
    "    Retrieve info for given region (by number)\n",
    "    Input: - file_info: json file with attributes\n",
    "           - file_node: The number each attribute for each node\n",
    "    Output: -r_info function:\n",
    "             For input i (region i+1) returns MNI coordinates, \n",
    "             lobe, Networks 1 and 2 and Broadmann area. \n",
    "    \"\"\"\n",
    "    with open(file_info, \"r\") as read_file:\n",
    "        dict_info = json.load(read_file)\n",
    "    read_file.close()\n",
    "    with open(file_nodes, \"r\") as read_file:\n",
    "        dict_nodes = json.load(read_file)\n",
    "    read_file.close()\n",
    "    \n",
    "    def r_info(i):\n",
    "        info=dict_nodes[\"rois\"][i]\n",
    "    \n",
    "        l=str(info['attr'][0])\n",
    "        n1=str(info['attr'][2])\n",
    "        b=str(info['attr'][3])\n",
    "        n2=str(info['attr'][4])\n",
    "        \n",
    "        result=dict()\n",
    "        result['MNI']=[info['x'],info['y'],info['z']]\n",
    "        result['Lobe']= dict_info['gui_Lobes'][l]\n",
    "        result['Network']=dict_info['gui_Networks'][n1]\n",
    "        result['Network2']=dict_info['gui_Networks2'][n2]\n",
    "        result['Brodmann Area']=dict_info['gui_BrodLabels'][b]\n",
    "        \n",
    "        return(result)\n",
    "    return(r_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For regions\n",
    "<ol> \n",
    "    <li> create limits\n",
    "    <li> regions_from_json\n",
    "    <li> sort_by_lobes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_limits(lengths):\n",
    "    \"\"\"\n",
    "    Create the indices based on lengths\n",
    "    \"\"\"\n",
    "    l=len(lengths)+1\n",
    "    lim=list(np.zeros(l))\n",
    "    for i in range(l):\n",
    "        lim[i]=int(np.sum(lengths[:i]))\n",
    "    return(lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regions_from_json(file,keys=None,verbose=True):\n",
    "    \"\"\"\n",
    "    Return for each key the list of indices and the total size\n",
    "    Input:  -file: file with information\n",
    "            -keys: list of keys\n",
    "            -verbose: If true print key and size\n",
    "    \"\"\"\n",
    "    with open(file, \"r\") as read_file:\n",
    "        info = json.load(read_file)\n",
    "    lista=[]\n",
    "    tam=[]\n",
    "    if keys is None:\n",
    "        keys=info.keys()\n",
    "    for key in keys:\n",
    "        if verbose:\n",
    "            print(key)\n",
    "            print(len(info[key]))\n",
    "        tam=tam+[len(info[key])]\n",
    "        lista=lista+info[key]\n",
    "    lista=np.array(lista)-1\n",
    "    return({'array':lista,'length':tam})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_lobes(vector):\n",
    "    lobes=np.array([22, 33, 37, 50, 71, 82, 99, 119,128,133,\n",
    "                    157,167,170,184,202,216,235,256,264,268])-1\n",
    "    lobes2=np.zeros(len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        lobe=np.sum(lobes < vector[i]) % 10\n",
    "        lobes2[i]=lobe\n",
    "    my_order=np.argsort(lobes2)\n",
    "    return(my_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics\n",
    "<ol>\n",
    "    <li> find_alpha_by_density\n",
    "    <li> full_correlation \n",
    "    <li> my_avg\n",
    "    <li> network_efficiency\n",
    "    <li> network_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_alpha_by_density(array,limit=50,alpha=0,step=0.01):\n",
    "    total = 100\n",
    "    while total > 0:\n",
    "        t,r= array.shape\n",
    "        density=np.zeros(t)\n",
    "        for i in range(t):\n",
    "            density[i]=np.sum(array[i,:]>alpha)*100/r\n",
    "        total=np.sum(density>limit)\n",
    "        alpha=alpha+step\n",
    "        \n",
    "    return(alpha-step)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy.stats import zscore\n",
    "def full_correlation(block,array,inter=True,summary_statistic=None):\n",
    "    (t,r1,r2) = block.shape\n",
    "    if t != len(array):\n",
    "        raise ValueError(\"array has not same dimensions as block\")\n",
    "    if inter:\n",
    "        corr=[]\n",
    "        for i in range(r1):\n",
    "            for j in range(r2):\n",
    "                x= np.corrcoef(zscore(block[:,i,j]),zscore(array))[0,1]\n",
    "                if math.isnan(x):\n",
    "                    corr.append(0)\n",
    "                else:\n",
    "                    corr.append(x)        \n",
    "    else:\n",
    "        corr=[]\n",
    "        for i in range(r1):\n",
    "            for j in range(i+1,r1):\n",
    "                x= np.corrcoef(zscore(block[:,i,j]),zscore(array))[0,1]\n",
    "                if math.isnan(x):\n",
    "                    corr.append(0)\n",
    "                else:\n",
    "                    corr.append(x) \n",
    "\n",
    "    if summary_statistic == np.mean:\n",
    "        corr = np.tanh(summary_statistic(corr))\n",
    "    elif summary_statistic == np.median:    \n",
    "        corr = summary_statistic(corr)\n",
    "    elif not summary_statistic:\n",
    "        corr\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized summary_statistic! Use None, np.median, or np.mean.\")\n",
    "    \n",
    "    return(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_avg(x,blocks):\n",
    "    y=np.copy(x)\n",
    "    r=blocks.shape[0]\n",
    "    for i in range(r):\n",
    "        a=blocks[i,0]-1\n",
    "        b=blocks[i,1]-1\n",
    "        for j in np.arange(a,b+1):\n",
    "            y[j]=np.mean(x[a:(b+1)])\n",
    "    return(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_efficiency(block,inter=True,positive=True):\n",
    "    \"\"\"\n",
    "    Measure of strength of connections within and between networks.\n",
    "    The weight between networks is based on \n",
    "    \"Dynamics of Intersubject Brain Networks during Anxious Anticipation\"\n",
    "    Najafi M., Kinnison J. and Pessoa L. 2017.\n",
    "    Input: - block: connections between N1 and N2 networks.\n",
    "           The dimension of the block (r1,r2) correspond the sizes of the networks\n",
    "           - alpha: set the threshold for the weights\n",
    "           - inter: If True the block represents two differents networks\n",
    "           otherwise is the same network\n",
    "           -positive: If True only consider positives weights otherwise\n",
    "           only the negatives are considered\n",
    "    Output: Strength of connections between networks \n",
    "    \"\"\"\n",
    "    (r1,r2) = block.shape\n",
    "    if positive:\n",
    "        new_block=block*(block>0)\n",
    "    else:\n",
    "        new_block=block*(block<0)\n",
    "    array=np.ndarray.flatten(new_block)\n",
    "    array=array[array != 0]\n",
    "    w=np.sum(1/array)\n",
    "    if inter:\n",
    "        return(w/(r1*r2))\n",
    "    else:\n",
    "        if r1==r2:\n",
    "            return(w/(r1*(r1-1)))\n",
    "        else:\n",
    "            warnings.warn('is not a square matrix for intra weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_weight(block,alpha=0,inter=True,positive=True):\n",
    "    \"\"\"\n",
    "    Measure of strength of connections within and between networks.\n",
    "    The weight between networks is based on \n",
    "    \"Dynamics of Intersubject Brain Networks during Anxious Anticipation\"\n",
    "    Najafi M., Kinnison J. and Pessoa L. 2017.\n",
    "    Input: - block: connections between N1 and N2 networks.\n",
    "           The dimension of the block (r1,r2) correspond the sizes of the networks\n",
    "           - alpha: set the threshold for the weights\n",
    "           - inter: If True the block represents two differents networks\n",
    "           otherwise is the same network\n",
    "           -positive: If True only consider positives weights otherwise\n",
    "           only the negatives are considered\n",
    "    Output: Strength of connections between networks \n",
    "    \"\"\"\n",
    "    (r1,r2) = block.shape\n",
    "    if positive:\n",
    "        new_block=block*(block>alpha)\n",
    "    else:\n",
    "        new_block=block*(block<-alpha)\n",
    "    w=np.sum(new_block)\n",
    "    if inter:\n",
    "        return(w/(r1*r2))\n",
    "    else:\n",
    "        if r1==r2:\n",
    "            return(w/(r1*(r1-1)))\n",
    "        else:\n",
    "            warnings.warn('is not a square matrix for intra weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Distance\n",
    "<ol>\n",
    "    <li> dyn_corr_isc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform\n",
    "from scipy.stats import pearsonr\n",
    "def dyn_corr_isc(D, slide,verbose=True,summary_statistic=None):\n",
    "    \"\"\"Intersubject correlation\n",
    "    For each moment in time compute the Pearson correlation between \n",
    "    the time series of length slide for each pair of voxels or ROI's, \n",
    "    defining a matrix correlation. If summary_statistic is None, return \n",
    "    t values (total time - slide) x R*(R-1)/2 values of Pearson correlation\n",
    "    values for each subject. Alternatively, supply either\n",
    "    np.mean or np.median to compute summary statistic (Fisher Z will\n",
    "    be applied and inverted if using mean).\n",
    "        \n",
    "    The implementation is based on Scha professor's code\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list or ndarray\n",
    "        fMRI data for which to compute ISC\n",
    "        \n",
    "    pairwise : bool, default: False\n",
    "        Whether to use pairwise (True) or leave-one-out (False) approach\n",
    "        \n",
    "    summary_statistic : None\n",
    "        Return all ISCs or collapse using np.mean or np.median\n",
    "    Returns\n",
    "    -------\n",
    "    iscs : subjects or pairs by pair of voxels ndarray\n",
    "        ISC for each subject or pair (or summary statistic) per pair of voxels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Infer subjects, TRs, voxels and print for user to check\n",
    "    n_subjects = D.shape[2]\n",
    "    n_TRs = D.shape[0]\n",
    "    n_voxels = D.shape[1]\n",
    "    \n",
    "    \n",
    "    print(f\"Assuming {n_subjects} subjects with {n_TRs} time points \"\n",
    "          f\"and {n_voxels} voxel(s) or ROI(s).\\n\")\n",
    "          #f\"Will compute sliding window analysis with a window length of -{neg_win} and +{pos_win} samples.\")\n",
    "    \n",
    "    t_wind=n_TRs+1-slide\n",
    "    corr_din=np.zeros((t_wind, int(n_voxels*( n_voxels-1)/2),n_subjects))        \n",
    "    \n",
    "    for s in range(n_subjects):\n",
    "        if verbose:\n",
    "            progress = 100 * (s/n_subjects)\n",
    "            sys.stdout.write(\"\\r%d%%\" % progress)\n",
    "            sys.stdout.flush() \n",
    "        for t in range(t_wind):\n",
    "            D_new=np.corrcoef(D[t:t+slide,:,s].T)-np.identity(n_voxels)\n",
    "            corr_din[t,:,s]=squareform(D_new,checks=False)\n",
    "    \n",
    "    if summary_statistic == np.mean:\n",
    "        corr_din = np.tanh(summary_statistic(np.arctanh(corr_din), axis=2))\n",
    "    elif summary_statistic == np.median:    \n",
    "        corr_din = summary_statistic(corr_din, axis=2)\n",
    "    elif not summary_statistic:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized summary_statistic! Use None, np.median, or np.mean.\")\n",
    "    \n",
    "    return corr_din"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter\n",
    "<ol>\n",
    "<li> affinity_matrix\n",
    "<li> check_connected\n",
    "<li> cmdscale\n",
    "<li> DFS\n",
    "<li> my_isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def affinity_matrix(D,n_neighbors=5,ignore=0,heat_kernel=False,sigma=1,verbose=False):\n",
    "    \"\"\"\n",
    "    Define the affinity martix for a given matrix distance\n",
    "    Input:  -D: Distance matrix\n",
    "            -n_neighbors: Number of considered closest neighbors for each node\n",
    "            -ignore: Number of ignored closest neighbors (n_neighbors is kept)\n",
    "            -heat_kernel: if False (default) edge weights are set to 1 \n",
    "            otherwise are set to exp(-D[i,j]**2/sig) \n",
    "            -sig : normalize factor for heat kernel\n",
    "            -verbose: if True print each node ad neighbors\n",
    "    Output: -aff: Affinitiy matrix (in csr format)\n",
    "    \"\"\"\n",
    "    m=D.shape[0]\n",
    "    n=D.shape[1]\n",
    "    if(m != n):\n",
    "        raise ValueError(\"D is not a square matrix\")\n",
    "    else:\n",
    "        aff=np.zeros((m,m))\n",
    "        for i in range(m):\n",
    "            diss=D[i,:] #Distance with all \n",
    "            idx = np.argsort(-diss)[::-1] #Sort indices ascending\n",
    "            idx = idx[1+ignore:n_neighbors+1+ignore] #Take n neighbors (ignore itself)\n",
    "            if (heat_kernel):\n",
    "                if verbose:\n",
    "                    print(\"i=%s, %s\" %(i,idx))\n",
    "                for j in idx:\n",
    "                    aff[i,j]=np.exp(-D[i,j]**2/sigma)\n",
    "                    aff[j,i]=aff[i,j]\n",
    "            else:\n",
    "                if (verbose == 1):\n",
    "                    print(\"i=%s, %s\" %(i,idx))\n",
    "                aff[i,idx]=1 #Set ones to neighbors\n",
    "                aff[idx,i]=1\n",
    "    aff=csr_matrix(aff)\n",
    "    return aff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_connected(aff):\n",
    "    \"\"\"\n",
    "    Checks if the affinity matrix aff represents a connected graph\n",
    "    Input: -aff: Affinitu matrix\n",
    "    Output: True or False \n",
    "    \"\"\"\n",
    "    total=aff.shape[0]\n",
    "    visited=[]\n",
    "    DFS(aff,visited,0)\n",
    "    return(total==len(visited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmdscale(D,n_components=2):\n",
    "    \"\"\"                                                                                       \n",
    "    Classical multidimensional scaling (MDS)                                                  \n",
    "    From https://github.com/meccaLeccaHi/mech_turk/blob/master/analyze/cmdscale.py                                                                                    \n",
    "    Parameters                                                                                \n",
    "    ----------                                                                                \n",
    "    D : (n, n) array                                                                          \n",
    "        Symmetric distance matrix.                                                            \n",
    "                                                                                               \n",
    "    Returns                                                                                   \n",
    "    -------                                                                                   \n",
    "    Y : (n, p) array                                                                          \n",
    "        Configuration matrix. Each column represents a dimension. Only the                    \n",
    "        p dimensions corresponding to positive eigenvalues of B are returned.                 \n",
    "        Note that each dimension is only determined up to an overall sign,                    \n",
    "        corresponding to a reflection.                                                        \n",
    "                                                                                               \n",
    "    e : (n,) array                                                                            \n",
    "        Eigenvalues of B.                                                                     \n",
    "                                                                                               \n",
    "    \"\"\"\n",
    "    # Number of points                                                                        \n",
    "    n = len(D)\n",
    " \n",
    "    # Centering matrix                                                                        \n",
    "    H = np.eye(n) - np.ones((n, n))/n\n",
    " \n",
    "    # YY^T                                                                                    \n",
    "    B = -H.dot(D**2).dot(H)/2\n",
    " \n",
    "    # Diagonalize                                                                             \n",
    "    evals, evecs = np.linalg.eigh(B)\n",
    " \n",
    "    #Takes only positive-eigenvalued components\n",
    "    w, = np.where(evals > 0)\n",
    "    evals=evals[w]\n",
    "    evecs=evecs[:,w]\n",
    "    idx   = np.argsort(evals)[::-1]\n",
    "    if (n_components<= len(idx)):\n",
    "        idx=idx[:n_components]\n",
    "    else:\n",
    "        warnings.warn('Number of components %s is greater than positive eigenvalues %s' %(n_components,len(idx)))\n",
    "        \n",
    "    # Sort by eigenvalue in descending order                                                  \n",
    "    evals = evals[idx]\n",
    "    V = evecs[:,idx]\n",
    " \n",
    "    # Compute the coordinates using positive-eigenvalued components only                      \n",
    "    \n",
    "    L  = np.diag(np.sqrt(evals))\n",
    "    Y  = V.dot(L)\n",
    " \n",
    "    return Y, evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(aff,visited,node):\n",
    "    \"\"\"\n",
    "    Depth-first search algorithm.\n",
    "    Input:  -aff: Affinity matrix\n",
    "            -visited: list to be populated with visited nodes\n",
    "            -node: initial node\n",
    "    Returns a populated list of visited nodes from initial node (node)\n",
    "    \"\"\"\n",
    "    if node not in visited:\n",
    "        #print(node)\n",
    "        visited.append(node) \n",
    "        vecinos=np.where(aff[node,:]!=0)[0]\n",
    "        #print(vecinos)\n",
    "        for veci in vecinos:\n",
    "            DFS(aff,visited,veci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors, kneighbors_graph\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.utils.graph_shortest_path import graph_shortest_path\n",
    "\n",
    "def my_isomap (X,n_neighbors=5, n_components=2, eigen_solver='auto', \n",
    "               eps=0.001, max_iter=300, path_method='auto',random_states=[None],\n",
    "               neighbors_algorithm='auto', n_jobs=None, solver=\"cmds\",\n",
    "               metric='minkowski', p=2, metric_params=None):\n",
    "        \n",
    "    nbrs = NearestNeighbors(n_neighbors= n_neighbors,\n",
    "                                      algorithm=neighbors_algorithm,\n",
    "                                      metric=metric, p=p,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_jobs=n_jobs)\n",
    "    \n",
    "    nbrs.fit(X)\n",
    "    kng = kneighbors_graph(nbrs, n_neighbors,\n",
    "                           metric= metric, p=p,\n",
    "                           metric_params=metric_params,\n",
    "                           mode='distance', n_jobs=n_jobs)\n",
    "    kng=(kng + kng.T)/2\n",
    "    \n",
    "    dist_matrix = graph_shortest_path(kng,method=path_method,\n",
    "                                      directed=False)\n",
    "    print(dist_matrix.shape)\n",
    "    \n",
    "    if solver == 'cmds':\n",
    "        embedding = cmdscale(dist_matrix,n_components=p)[0]\n",
    "    elif solver == 'mmds':\n",
    "        st=1e10\n",
    "        for r_state in random_states:\n",
    "            mds=MDS(n_components=p,metric=True,dissimilarity='precomputed',max_iter=max_iter,random_state=r_state,eps=eps)\n",
    "            new_emb = mds.fit_transform(dist_matrix)\n",
    "            if (mds.stress_< st):\n",
    "                emb=new_emb\n",
    "                st=mds.stress_\n",
    "                print(\"st=%s, r=%s\" %(st,r_state))\n",
    "        embedding=emb\n",
    "    else:\n",
    "        raise Exception(\"Sorry, solver must be cmds or mmds\")\n",
    "    \n",
    "    return(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test statistic\n",
    "<ol>\n",
    "    <li> phase_shift\n",
    "    <li> surrogate_dyn_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: 74x193\n",
    "def phase_shift(X):\n",
    "    r,t = X.shape\n",
    "    Y=np.fft.rfft(X)\n",
    "    amp=np.abs(Y)\n",
    "    angle = np.angle(Y)\n",
    "\n",
    "    prng= np.random.RandomState(None)\n",
    "\n",
    "    random_vec= prng.rand(1,angle.shape[1])*2*np.math.pi \n",
    "    angle2 = angle + random_vec\n",
    "    amp2= amp*(np.cos(angle2)+1j*np.sin(angle2))\n",
    "\n",
    "    Y2= np.fft.irfft(amp2,n=t) \n",
    "    \n",
    "    return(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def surrogate_dyn_corr(data, slide, n_shifts=1000, cut=100,path=''):\n",
    "    \"\"\"Phase randomization for dyn_corr\n",
    "    \n",
    "    For each pair of ROIs compute a null distribution of \n",
    "    dyn_corr where time series for each subjest are phase \n",
    "    randomized prior to computing dyn_corr. \n",
    "    \n",
    "    Input:- data: Matrix of data. Size = (time_points, regions, and n_subjects)\n",
    "          - slide: Size of window for corr_dyn (size in second= slide*TR)\n",
    "        - - n_shifts: Number of copies of surrogate data. Default set to 1000\n",
    "          - cut: Cut proces for cut subjects everytime for generate corr_dyn \n",
    "          (to not crash my computer). Default set to 100\n",
    "          - path: Path of folder where surrogate copies will be stored.\n",
    "            If not specified \n",
    "    At the end we generate n_shifts copies for dyn_corr output\n",
    "    \"\"\"\n",
    "    \n",
    "    n_TRs = data.shape[0]\n",
    "    n_regions = data.shape[1]\n",
    "    n_subjects = data.shape[2]\n",
    "    \n",
    "    for j in range(n_shifts):\n",
    "        surrogate=[]\n",
    "        for i in range(n_subjects):\n",
    "            X=data[:,:,i].T\n",
    "            Y=phase_shift(X)\n",
    "            surrogate.append(Y.T)\n",
    "        \n",
    "        s_data=np.stack(surrogate,axis=2)    \n",
    "        \n",
    "        r=n_subjects % cut\n",
    "        if r == 0:\n",
    "            k = int(n_subjects/cut)\n",
    "        else:\n",
    "            k = int(n_subjects/cut) + 1\n",
    "            \n",
    "        slidings=[]    \n",
    "        for i in range(k):\n",
    "            sliding=dyn_corr_isc(s_data[:,:,i*cut:(i+1)*cut],slide=slide,verbose=False,summary_statistic=np.mean)\n",
    "            slidings.append(sliding)\n",
    "            time.sleep(10)\n",
    "\n",
    "        sliding_all=np.mean(np.stack(slidings,axis=2),axis=2)\n",
    "        \n",
    "        if i<10:\n",
    "            name=path+'/'+'sliding_all_'+'00'+str(j)+'.npy'\n",
    "        elif i<100:\n",
    "            name=path+'/'+'sliding_all_'+'0'+str(j)+'.npy'\n",
    "        else:\n",
    "            name=path+'/'+'sliding_all_'+str(j)+'.npy'\n",
    "            \n",
    "        np.save(name,sliding_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchoring\n",
    "<ol>\n",
    "    <li> bapply\n",
    "    <li> compare_2samples\n",
    "    <li> critical_kolmogorov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement,product\n",
    "#================================================================\n",
    "#bapply applies a matrix function on blocks of the matrix M\n",
    "#Input:   -FUN: Function to be applied\n",
    "#         -M: Matrix\n",
    "#         -X,Y: List or matrix of intervals (n x 2). A element \n",
    "#         of the list or row would be c(1,5) representing the interval between indices 1 and 5\n",
    "#         -comb: Use all combinations of intervals in X and Y, Otherwise the intervals will be matched\n",
    "#         one to one\n",
    "# Output: List of results of FUN applied to defined blocks\n",
    "def bapply(FUN,M,X,Y=None,comb=False):\n",
    "    def block_from_index(A,B,index):\n",
    "        j1=index[0]\n",
    "        j2=index[1]\n",
    "        int1=A[j1,:]\n",
    "        int2=B[j2,:]\n",
    "        block=M[int1[0]:(int1[1]+1),int2[0]:(int2[1]+1)]\n",
    "        return(block)\n",
    "    \n",
    "    if isinstance(X, list):\n",
    "        X=np.array(X)\n",
    "        \n",
    "    if(X.shape[1]!=2):\n",
    "        warnings.warn('X must have 2 columns')\n",
    "    \n",
    "    if(Y != None):\n",
    "        if isinstance(Y, list):\n",
    "            Y=np.array(Y)\n",
    "        \n",
    "        if(Y.shape[1]!=2):\n",
    "            warnings.warn('Y must have 2 columns')\n",
    "        rY=Y.shape[0]\n",
    "    \n",
    "    rX=X.shape[0]\n",
    "    if (comb): #comb is True\n",
    "        if (Y == None):\n",
    "            index=list(combinations_with_replacement(range(rX),2))\n",
    "            Y=X\n",
    "        \n",
    "        else:\n",
    "            index=list(product(range(rX),range(rX)))\n",
    "        \n",
    "    else:\n",
    "        index=np.reshape([np.arange(rX),np.arange(rX)],(2,rX)).T\n",
    "        if(Y != None):\n",
    "            if (rX != rY):\n",
    "                warnings.warn(\"X and Y must have same dimensions\")\n",
    "        else:\n",
    "            Y=X\n",
    "        \n",
    "    result=list()\n",
    "    for i in range(len(index)):\n",
    "        block=block_from_index(X,Y,index[i])\n",
    "        result.append(FUN(block))\n",
    "    \n",
    "    return(result)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp,median_test, kruskal\n",
    "def compare_2samples(x1,x2,stat_fun,params=None):\n",
    "    '''\n",
    "    Compute the stat_fun statisctic on 2 samples.\n",
    "    Input: -x1, x2: Lists of arrays . The contained arrays must have\n",
    "            the same dimensions m x n\n",
    "           -stat_fun: Statistic to compare 1-D samples\n",
    "           -params: Especifically params list for stat_fun (later)\n",
    "    Output: -stat: Test statistic of size m x n\n",
    "            -p: The p-value of test of size m x n\n",
    "    '''\n",
    "    n1=len(x1)\n",
    "    n2=len(x2)\n",
    "    print(\"Samples of\", n1, \"and\", n2, \"elements\")\n",
    "    dim=np.shape(x1[1])\n",
    "    \n",
    "    if len(dim) == 1:\n",
    "        t=dim[0]\n",
    "        stat=np.zeros(t)\n",
    "        p=np.zeros(t)\n",
    "        \n",
    "        for i in range(t):\n",
    "            sample1=np.zeros(n1)\n",
    "            sample2=np.zeros(n2)\n",
    "            \n",
    "            for j in range(n1):\n",
    "                sample1[j]=x1[j][i]\n",
    "                \n",
    "            for j in range(n2):\n",
    "                sample2[j]=x2[j][i]\n",
    "    \n",
    "            result=stat_fun(sample1,sample2)\n",
    "            stat[i]=result[0]\n",
    "            p[i]=result[1]\n",
    "        \n",
    "    return([stat,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_kolmogorov(alpha,n1,n2):\n",
    "    c_alpha = {\n",
    "      0.10: 1.22,\n",
    "      0.05: 1.36,\n",
    "      0.025: 1.48,\n",
    "      0.01: 1.63,\n",
    "      0.005: 1.73,\n",
    "      0.001: 1.95\n",
    "    } \n",
    "    c=c_alpha[alpha]\n",
    "    D=c*np.sqrt((n1+n2)/(n1*n2))\n",
    "    return(D)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot\n",
    "<ol>\n",
    "    <li> colorline\n",
    "    <li> make_segments\n",
    "    <li> truncate_colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib.path as mpath\n",
    "\n",
    "def colorline(\n",
    "    x, y, z=None, cmap=plt.get_cmap('copper'), norm=plt.Normalize(0.0, 1.0),\n",
    "        linewidth=3, alpha=1.0,zorder=1):\n",
    "    \"\"\"\n",
    "    http://nbviewer.ipython.org/github/dpsanders/matplotlib-examples/blob/master/colorline.ipynb\n",
    "    http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    Plot a colored line with coordinates x and y\n",
    "    Optionally specify colors in the array z\n",
    "    Optionally specify a colormap, a norm function and a line width\n",
    "    \"\"\"\n",
    "\n",
    "    # Default colors equally spaced on [0,1]:\n",
    "    if z is None:\n",
    "        z = np.linspace(0.0, 1.0, len(x))\n",
    "\n",
    "    # Special case if a single number:\n",
    "    if not hasattr(z, \"__iter__\"):  # to check for numerical input -- this is a hack\n",
    "        z = np.array([z])\n",
    "\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    segments = make_segments(x, y)\n",
    "    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,\n",
    "                              linewidth=linewidth, alpha=alpha,zorder=zorder)\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segments(x, y):\n",
    "    \"\"\"\n",
    "    Create list of line segments from x and y coordinates, in the correct format\n",
    "    for LineCollection: an array of the form numlines x (points per line) x 2 (x\n",
    "    and y) array\n",
    "    \"\"\"\n",
    "\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matlab thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import scipy.io\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#----------------------------  find_structure ---------------------------\n",
    "#This function converts MNI coordinate to a description of brain structure in aal\n",
    "#Input: - mni : the coordinates (MNI) of some points, in mm.  It is Mx3 matrix\n",
    "#where each row is the coordinate for one point.\n",
    "#        -DB (optional): The database. If is omit, make sure TDdatabase.mat is in the \n",
    "#        same folder\n",
    "#Output: -one_line_result: A list of M elements, each describing each point.\n",
    "#        -table_result:  A  MxN matrix being N the size of the database (DB)\n",
    "#\n",
    "def find_structure(mni,DB=None):\n",
    "    #Vectorize this functions\n",
    "    vstr=np.vectorize(str)\n",
    "    vround = np.vectorize(my_round)\n",
    "    vint=np.vectorize(int)\n",
    "    \n",
    "    if DB is None:\n",
    "        mat=scipy.io.loadmat('../Data/TDdatabase.mat')  \n",
    "            \n",
    "    mni=np.array(mni)        \n",
    "    \n",
    "    #round coordinates\n",
    "    mni=vround(mni/2)*2 \n",
    "    \n",
    "    T=np.array([[2 ,0 ,0 ,-92],[0,2,0,-128],\n",
    "                    [0,0,2,-74],[0,0,0,1]])\n",
    "    \n",
    "    index=mni2cor(mni,T)\n",
    "    M=np.shape(index)[0]\n",
    "    \n",
    "    #-1 by python indexation\n",
    "    index=vint(index) - 1 \n",
    "    \n",
    "    N=np.shape(mat['DB'])[1]\n",
    "    table_result=np.zeros((M,N))\n",
    "    table_result=table_result.tolist() #instead of [i,j] use [i][j]\n",
    "    \n",
    "    one_line_result=[\"\"] * M\n",
    "    \n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            #mat['DB'][0,j][0,0][0] is the j-th 3D-matrix \n",
    "            graylevel=mat['DB'][0,j][0,0][0][index[i,0],index[i,1],index[i,2]] \n",
    "            if graylevel == 0:\n",
    "                 label = 'undefined'\n",
    "            else:\n",
    "                if j < (N-1):\n",
    "                    tmp = ''\n",
    "                else:\n",
    "                    tmp =' (aal)' \n",
    "                    \n",
    "                #mat['DB'][0,j][0,0][1]  is the list with regions\n",
    "                label=mat['DB'][0,j][0,0][1][0,(graylevel-1)][0] + tmp\n",
    "            \n",
    "            table_result[i][j]=label\n",
    "            one_line_result[i] = one_line_result[i] + ' // ' + label\n",
    "    return(one_line_result,table_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------- mni2cor --------------------------------\n",
    "def mni2cor(mni,T=np.array([[-4 ,0 ,0 ,84],[0,4,0,-116],\n",
    "                    [0,0,4,-56],[0,0,0,1]])):\n",
    "    \"\"\"\n",
    "    Convert mni coordinate to matrix coordinate\n",
    "    Input: - mni : the coordinates (MNI) of some points, in mm.  It is Mx3 matrix\n",
    "           where each row is the coordinate for one point.\n",
    "           -T (optional): transform matrix coordinate is the returned coordinate in matrix.\n",
    "    Output: -coords : Coordinate matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    mni=np.array(mni)\n",
    "    \n",
    "    if len(np.shape(mni))==1:\n",
    "        mni=mni.reshape((1, len(mni)))\n",
    "    \n",
    "    if np.shape(mni)[1] != 3:\n",
    "        warnings.warn('are not 3-length coordinates')\n",
    "        return(np.array([]))\n",
    "        \n",
    "    a=np.hstack((mni,np.ones((np.shape(mni)[0],1))))\n",
    "    b=np.transpose(np.linalg.inv(T))\n",
    "    coords=a.dot(b)\n",
    "    coords=coords[:,0:3]\n",
    "        \n",
    "    vround = np.vectorize(my_round)\n",
    "    coords = vround(coords)\n",
    "    return(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#----------------- my_round -------------------\n",
    "#Integer rounding that behaves like round from MATLAB\n",
    "def my_round(x):\n",
    "    r=x-np.floor(x)\n",
    "    if(r == 0.5):\n",
    "        if x<0: return(x-0.5)\n",
    "        else: return(x+0.5)\n",
    "    else:\n",
    "        return(round(x))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
